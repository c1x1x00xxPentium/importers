{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/alex/Downloads/stats/\")\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from db import connection\n",
    "from db_utils import DBUtils\n",
    "import xlrd\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['UN WPP - Total population (both sexes combined) by single age, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "        'UN WPP - Male population by single age, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "         'UN WPP - Female population by single age, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "         'UN WPP - Interpolated demographic indicators by region, subregion and country, annually for 1950-2099',\n",
    "          'UN WPP - Interpolated total population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "          'UN WPP - Interpolated male population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "          'UN WPP - Interpolated female population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "          'UN WPP - Percentage of total population by broad age group, region, subregion and country, annually interpolated for 1950-2100',\n",
    "          'UN WPP - Percentage of male total population by broad age group, region, subregion and country, annually interpolated for 1950-2100',\n",
    "          'UN WPP - Percentage of female total population by broad age group, region, subregion and country, annually interpolated for 1950-2100',\n",
    "          'UN WPP - Dependency ratios (total, child, old-age) for different age groups and for both sexes combined by region, subregion and country, annually interpolated for 1950-2100',\n",
    "          'UN WPP - Male dependency ratios (total, child, old-age) for different age groups by region, subregion and country, annually interpolated for 1950-2100',\n",
    "          'UN WPP - Female dependency ratios (total, child, old-age) for different age groups by region, subregion and country, annually interpolated for 1950-2100'\n",
    "         ]\n",
    "\n",
    "keys = ['Annual population by single age - Both Sexes. De facto population as of 1 July of the year indicated classified by single age (0, 1, 2, ..., 99, 100+). Data are presented in thousands.',\n",
    "       'Annual population by single age - Male. De facto population as of 1 July of the year indicated classified by single age (0, 1, 2, ..., 99, 100+). Data are presented in thousands.',\n",
    "       'Annual population by single age - Female. De facto population as of 1 July of the year indicated classified by single age (0, 1, 2, ..., 99, 100+). Data are presented in thousands.',\n",
    "       'Annually interpolated demographic indicators.',\n",
    "       'Annual total population (both sexes combined) by broad age groups. Data are presented in thousands.',\n",
    "       'Annual male population by broad age groups. Data are presented in thousands.',\n",
    "        'Annual female population by broad age groups. Data are presented in thousands.',\n",
    "        'Percentage of annual total population (both sexes combined) by broad age group.',\n",
    "        'Percentage of annual male total population by broad age groups.',\n",
    "        'Percentage of annual female total population by broad age groups.',\n",
    "        'Annual dependency ratios (total, child, old-age) for different age groups and for both sexes combined.',\n",
    "        'Annual male dependency ratios (total, child, old-age) for different age groups.',\n",
    "        'Annual female dependency ratios (total, child, old-age) for different age groups.'\n",
    "       ]\n",
    "datasets_dict = {}\n",
    "for x,y in zip(keys, values):\n",
    "    datasets_dict[x] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with connection as c:\n",
    "#     db = DBUtils(c)\n",
    "    \n",
    "#     # upsert datasets\n",
    "#     dataset_name_ids = {}\n",
    "#     for f in tqdm(os.listdir('sources/')):\n",
    "#         if f == '.DS_Store':\n",
    "#             continue\n",
    "#         data = pd.read_excel('sources/'+f)\n",
    "#         val = data[data.columns[0]][8]\n",
    "#         index_to_remove = val.find(\":\")\n",
    "#         res = \"UN WPP - \" + val[index_to_remove+2:]\n",
    "#         dataset_id = db.upsert_dataset(name=res, namespace=\"unwpp\", user_id=15)\n",
    "#         dataset_name_ids[res] = dataset_id\n",
    "        \n",
    "#     # upsert sources\n",
    "    \n",
    "#     dataset_to_source_ids = {}\n",
    "#     source_name = \"United Nations – Population Division (2019 Revision)\"\n",
    "#     for addInfo, dataset_name in datasets_dict.items():\n",
    "#         description = {}\n",
    "#         description['dataPublishedBy'] = \"United Nations, Department of Economic and Social Affairs, Population Division (2019). World Population Prospects: The 2019 Revision, DVD Edition.\"\n",
    "#         description['dataPublisherSource'] = None\n",
    "#         description['link'] = 'https://population.un.org/wpp2019/Download/Standard/Interpolated/'\n",
    "#         description['retrievedDate'] = datetime.datetime.now().strftime(\"%d-%b-%Y\")\n",
    "#         description['additionalInfo'] = addInfo\n",
    "        \n",
    "#         source_id = db.upsert_source(name=source_name, description=json.dumps(description), dataset_id=dataset_name_ids[dataset_name])\n",
    "#         dataset_to_source_ids[dataset_name_ids[dataset_name]] = source_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_to_source_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [05:26<00:00, 23.69s/it]\n"
     ]
    }
   ],
   "source": [
    "names,ids = [], []\n",
    "i = 0\n",
    "for f in tqdm(glob('data/*.xlsx')):\n",
    "    \n",
    "        data = pd.read_excel(f)\n",
    "        val = data[data.columns[0]][8]\n",
    "        index_to_remove = val.find(\":\")\n",
    "        res = \"UN WPP - \" + val[index_to_remove+2:]\n",
    "        names.append(res)\n",
    "        ids.append(i)\n",
    "        i+=1\n",
    "datasets = pd.DataFrame()\n",
    "datasets['id'] = ids\n",
    "datasets['name'] = names\n",
    "datasets.to_csv('datasets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, desc, d_ids = [], [], []\n",
    "\n",
    "source_name = \"United Nations – Population Division (2019 Revision)\"\n",
    "for addInfo, dataset_name in datasets_dict.items():\n",
    "    description = {}\n",
    "    description['dataPublishedBy'] = \"United Nations, Department of Economic and Social Affairs, Population Division (2019). World Population Prospects: The 2019 Revision, DVD Edition.\"\n",
    "    description['dataPublisherSource'] = None\n",
    "    description['link'] = 'https://population.un.org/wpp2019/Download/Standard/Interpolated/'\n",
    "    description['retrievedDate'] = datetime.datetime.now().strftime(\"%d-%b-%Y\")\n",
    "    description['additionalInfo'] = addInfo\n",
    "    dataset_id = datasets[datasets['name'] == dataset_name]['id'].values[0]\n",
    "\n",
    "    names.append(source_name)\n",
    "    desc.append(description)\n",
    "    d_ids.append(dataset_id)\n",
    "    \n",
    "res = pd.DataFrame()\n",
    "res['name'] = names\n",
    "res['description'] = desc\n",
    "res['dataset_id'] = d_ids\n",
    "res.to_csv(\"sources.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataVariables():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        self.i = 0\n",
    "        self.ids = []\n",
    "        self.names = []\n",
    "        self.units = []\n",
    "        self.dataset_ids = []\n",
    "        self.doc_to_unit = {\n",
    "                        \"UN WPP - Female population by single age, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\",\n",
    "                        \"UN WPP - Male population by single age, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\",\n",
    "            \"UN WPP - Total population (both sexes combined) by single age, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\",\n",
    "            \"UN WPP - Female dependency ratios (total, child, old-age) for different age groups by region, subregion and country, annually interpolated for 1950-2100\": \"Female dependency ratios for different age groups\",\n",
    "            \"UN WPP - Male dependency ratios (total, child, old-age) for different age groups by region, subregion and country, annually interpolated for 1950-2100\": \"Male dependency ratios for different age groups\",\n",
    "            \"UN WPP - Dependency ratios (total, child, old-age) for different age groups and for both sexes combined by region, subregion and country, annually interpolated for 1950-2100\": \"Dependency ratios (both sexes combined) for different age groups\",\n",
    "            \"UN WPP - Percentage of female total population by broad age group, region, subregion and country, annually interpolated for 1950-2100\": \"Percentage\",\n",
    "            \"UN WPP - Percentage of male total population by broad age group, region, subregion and country, annually interpolated for 1950-2100\": \"Percentage\",\n",
    "            \"UN WPP - Percentage of total population by broad age group, region, subregion and country, annually interpolated for 1950-2100\": \"Percentage\",\n",
    "            \"UN WPP - Interpolated female population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\",\n",
    "            \"UN WPP - Interpolated male population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\",\n",
    "            \"UN WPP - Interpolated total population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\"\n",
    "            #UN WPP - Interpolated demographic indicators by region, subregion and country, annually for 1950-2099\n",
    "                   \n",
    "\n",
    "                    }\n",
    "        \n",
    "        self.datasets = pd.read_csv('datasets.csv')\n",
    "        self.df = pd.DataFrame()\n",
    "    \n",
    "        \n",
    "    def get_variables(self, path, skiprows=8, prefix=None):\n",
    "        \n",
    "        for sh in [\"ESTIMATES\", \"MEDIUM VARIANT\"]:\n",
    "            data = pd.read_excel(path, skiprows=skiprows, sheet_name=sh)\n",
    "\n",
    "            val = data[data.columns[0]][0]\n",
    "            index_to_remove = val.find(\":\")\n",
    "            res = \"UN WPP - \" + val[index_to_remove+2:]\n",
    "\n",
    "            title = data[data.columns[0]][1]\n",
    "            print(title)\n",
    "\n",
    "            for item in data.loc[7, data.columns[8]: data.columns[-1]].values:\n",
    "                if prefix:\n",
    "                    self.names.append(title + \": \" + prefix + \" - \" + item)\n",
    "                else:\n",
    "                    self.names.append(title + \": \" + item)\n",
    "                self.ids.append(self.i)\n",
    "                self.i+=1\n",
    "                self.units.append(self.doc_to_unit[res])\n",
    "                self.dataset_ids.append(self.datasets[self.datasets['name'] == res]['id'].values[0])\n",
    "    \n",
    "    def get_custom_variable(self, path, skiprows=8, prefix=None):\n",
    "        \n",
    "        column_unit = {\n",
    "            8: \"Thousands\",\n",
    "            9: \"Thousands\",\n",
    "            10: \"Thousands\",\n",
    "            11: \"Percentage\",\n",
    "            12: \"Years\",\n",
    "            13: \"Years\",\n",
    "            14: \"Years\",\n",
    "            15: \"Thousands\",\n",
    "            16: \"Infant deaths per 1,000 live births\",\n",
    "            17: \"Deaths under age 5 per 1,000 live births\",\n",
    "            18: \"Thousands\",\n",
    "            19: \"Births per 1,000 population\",\n",
    "            20: \"Live births per woman\",\n",
    "            21: \"Thousands\",\n",
    "            22: \"Per 1,000 population\",\n",
    "            23: \"Thousands\",\n",
    "            24: \"Percentage\"\n",
    "            \n",
    "        \n",
    "        }\n",
    "        \n",
    "        for sh in [\"ESTIMATES\", \"MEDIUM VARIANT\"]:\n",
    "            data = pd.read_excel(path, skiprows=skiprows, sheet_name=sh)\n",
    "\n",
    "            val = data[data.columns[0]][0]\n",
    "            index_to_remove = val.find(\":\")\n",
    "            res = \"UN WPP - \" + val[index_to_remove+2:]\n",
    "\n",
    "            title = data[data.columns[0]][1]\n",
    "            print(title)\n",
    "            \n",
    "            col_index = 8\n",
    "            for item in data.loc[7, data.columns[8]: data.columns[-1]].values:\n",
    "                if prefix:\n",
    "                    self.names.append(title + \": \" + prefix + \" - \" + item)\n",
    "                else:\n",
    "                    self.names.append(title + \": \" + item)\n",
    "                self.ids.append(self.i)\n",
    "                self.i+=1\n",
    "                self.units.append(column_unit[col_index])\n",
    "                self.dataset_ids.append(self.datasets[self.datasets['name'] == res]['id'].values[0])\n",
    "                col_index += 1\n",
    "           \n",
    "    \n",
    "\n",
    "            \n",
    "            \n",
    "    def get_df(self):\n",
    "        \n",
    "        self.df['id'] = self.ids\n",
    "        self.df['name'] = self.names\n",
    "        self.df['unit'] = self.units\n",
    "        self.df['dataset_id'] = self.dataset_ids\n",
    "        \n",
    "        return self.df\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1/13 [00:20<04:03, 20.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 2/13 [01:07<05:13, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 3/13 [02:27<07:17, 43.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 4/13 [03:44<08:05, 53.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 5/13 [04:03<05:45, 43.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2099\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 6/13 [04:49<05:08, 44.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 7/13 [05:11<03:45, 37.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 8/13 [06:27<04:05, 49.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 9/13 [07:12<03:11, 47.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 10/13 [07:31<01:57, 39.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 11/13 [08:14<01:21, 40.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 12/13 [08:58<00:41, 41.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 13/13 [09:41<00:00, 41.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dv = DataVariables()\n",
    "for f in tqdm(glob('data/*.xlsx')):\n",
    "     \n",
    "        if f == \"data/WPP2019_INT_F03_3_POPULATION_BY_AGE_ANNUAL_FEMALE.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Female population by age (thousands)\")\n",
    "            \n",
    "        elif f == \"data/WPP2019_INT_F03_2_POPULATION_BY_AGE_ANNUAL_MALE.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Male population by age (thousands)\")   \n",
    "        elif f == \"data/WPP2019_INT_F03_1_POPULATION_BY_AGE_ANNUAL_BOTH_SEXES.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Total population by age, both sexes combined (thousands)\")\n",
    "            \n",
    "        elif f == \"data/WPP2019_INT_F02C_3_ANNUAL_POPULATION_INDICATORS_DEPENDENCY_RATIOS_FEMALE.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Female dependency ratios for different age groups\")\n",
    "            \n",
    "        elif f == \"data/WPP2019_INT_F02C_2_ANNUAL_POPULATION_INDICATORS_DEPENDENCY_RATIOS_MALE.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Male dependency ratios for different age groups\")\n",
    "            \n",
    "        elif f == \"data/WPP2019_INT_F02C_1_ANNUAL_POPULATION_INDICATORS_DEPENDENCY_RATIOS_BOTH_SEXES.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Dependency ratios (both sexes combined) for different age groups\")\n",
    "            \n",
    "        elif f == \"data/WPP2019_INT_F02B_3_ANNUAL_POPULATION_INDICATORS_PERCENTAGE_FEMALE.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Percentage of female population by broad age group (per 100 female total population)\")\n",
    "            \n",
    "        elif f == \"data/WPP2019_INT_F02B_2_ANNUAL_POPULATION_INDICATORS_PERCENTAGE_MALE.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Percentage of male population by broad age group (per 100 male total population)\")\n",
    "            \n",
    "        elif f == \"data/WPP2019_INT_F02B_1_ANNUAL_POPULATION_INDICATORS_PERCENTAGE_BOTH_SEXES.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Percentage of total population by broad age group, both sexes combined (per 100 total population)\")\n",
    "            \n",
    "        elif f == \"data/WPP2019_INT_F02A_3_ANNUAL_POPULATION_INDICATORS_FEMALE.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Female population by broad age group (thousands)\")\n",
    "            \n",
    "        elif f == \"data/WPP2019_INT_F02A_2_ANNUAL_POPULATION_INDICATORS_MALE.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Male population by broad age group (thousands)\")\n",
    "            \n",
    "        elif f == \"data/WPP2019_INT_F02A_1_ANNUAL_POPULATION_INDICATORS_BOTH_SEXES.xlsx\":\n",
    "            dv.get_variables(f, prefix=\"Total population by broad age group, both sexes combined (thousands)\")\n",
    "            \n",
    "        elif f == \"data/WPP2019_INT_F01_ANNUAL_DEMOGRAPHIC_INDICATORS.xlsx\":\n",
    "            dv.get_custom_variable(f, prefix=\"Male population by age (thousands)\")\n",
    "    \n",
    "        \n",
    "\n",
    "res = dv.get_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"variables.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_country(row):\n",
    "        \n",
    "        row['country'] = row['country'].str.replace(r'\\s*[^A-Za-z\\s]*$', '')\n",
    "        return row\n",
    "\n",
    "\n",
    "def get_variables(path, variables, skiprows=8, prefix=None, custom=False):\n",
    "        \n",
    "        for sh in [\"ESTIMATES\", \"MEDIUM VARIANT\"]:\n",
    "            data = pd.read_excel(path, skiprows=skiprows, sheet_name=sh)\n",
    "\n",
    "            val = data[data.columns[0]][0]\n",
    "            index_to_remove = val.find(\":\")\n",
    "            res = \"UN WPP - \" + val[index_to_remove+2:]\n",
    "\n",
    "            title = data[data.columns[0]][1]\n",
    "            \n",
    "            index_col = 8\n",
    "            \n",
    "            for item in data.loc[7, data.columns[8]: data.columns[-1]].values:\n",
    "                \n",
    "                if prefix:\n",
    "                    var_name = title + \": \" + prefix + \" - \" + item\n",
    "                else:\n",
    "                    var_name = title + \": \" + item\n",
    "                \n",
    "                var_id = variables[variables['name'] == var_name]['id'].values[0] \n",
    "                \n",
    "                data2 = data.iloc[8:]\n",
    "               \n",
    "                data_res = pd.DataFrame()\n",
    "                data_res['country'] = data2[data2.columns[2]]\n",
    "                data_res['year'] = data2[data2.columns[7]]\n",
    "                data_res['value'] = data2[\"Unnamed: %s\" % str(index_col)]\n",
    "                \n",
    "                data_res['country'] = normalize_country(data_res)\n",
    "                data_res.to_csv('datapoints/datapoints_%s.csv' % str(var_id), index=False)\n",
    "                \n",
    "                index_col += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 1/13 [00:22<04:34, 22.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 2/13 [01:20<06:06, 33.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 3/13 [02:51<08:25, 50.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 4/13 [04:21<09:21, 62.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 5/13 [04:40<06:36, 49.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 6/13 [05:33<05:53, 50.55s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 7/13 [05:55<04:11, 41.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 8/13 [07:26<04:43, 56.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 9/13 [08:19<03:41, 55.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 10/13 [08:41<02:16, 45.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 11/13 [09:34<01:35, 47.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 12/13 [10:27<00:49, 49.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 13/13 [11:20<00:00, 50.34s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "variables = pd.read_csv(\"variables.csv\")\n",
    "\n",
    "for f in tqdm(glob('data/*.xlsx')):\n",
    "   \n",
    "\n",
    "    if f == \"data/WPP2019_INT_F03_3_POPULATION_BY_AGE_ANNUAL_FEMALE.xlsx\":\n",
    "            get_variables(f,variables, prefix=\"Female population by age (thousands)\")\n",
    "            \n",
    "    elif f == \"data/WPP2019_INT_F03_2_POPULATION_BY_AGE_ANNUAL_MALE.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Male population by age (thousands)\")   \n",
    "    elif f == \"data/WPP2019_INT_F03_1_POPULATION_BY_AGE_ANNUAL_BOTH_SEXES.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Total population by age, both sexes combined (thousands)\")\n",
    "\n",
    "    elif f == \"data/WPP2019_INT_F02C_3_ANNUAL_POPULATION_INDICATORS_DEPENDENCY_RATIOS_FEMALE.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Female dependency ratios for different age groups\")\n",
    "\n",
    "    elif f == \"data/WPP2019_INT_F02C_2_ANNUAL_POPULATION_INDICATORS_DEPENDENCY_RATIOS_MALE.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Male dependency ratios for different age groups\")\n",
    "\n",
    "    elif f == \"data/WPP2019_INT_F02C_1_ANNUAL_POPULATION_INDICATORS_DEPENDENCY_RATIOS_BOTH_SEXES.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Dependency ratios (both sexes combined) for different age groups\")\n",
    "\n",
    "    elif f == \"data/WPP2019_INT_F02B_3_ANNUAL_POPULATION_INDICATORS_PERCENTAGE_FEMALE.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Percentage of female population by broad age group (per 100 female total population)\")\n",
    "\n",
    "    elif f == \"data/WPP2019_INT_F02B_2_ANNUAL_POPULATION_INDICATORS_PERCENTAGE_MALE.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Percentage of male population by broad age group (per 100 male total population)\")\n",
    "\n",
    "    elif f == \"data/WPP2019_INT_F02B_1_ANNUAL_POPULATION_INDICATORS_PERCENTAGE_BOTH_SEXES.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Percentage of total population by broad age group, both sexes combined (per 100 total population)\")\n",
    "\n",
    "    elif f == \"data/WPP2019_INT_F02A_3_ANNUAL_POPULATION_INDICATORS_FEMALE.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Female population by broad age group (thousands)\")\n",
    "\n",
    "    elif f == \"data/WPP2019_INT_F02A_2_ANNUAL_POPULATION_INDICATORS_MALE.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Male population by broad age group (thousands)\")\n",
    "\n",
    "    elif f == \"data/WPP2019_INT_F02A_1_ANNUAL_POPULATION_INDICATORS_BOTH_SEXES.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Total population by broad age group, both sexes combined (thousands)\")\n",
    "\n",
    "    elif f == \"data/WPP2019_INT_F01_ANNUAL_DEMOGRAPHIC_INDICATORS.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Male population by age (thousands)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get country names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/356 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 3/356 [00:00<00:13, 26.30it/s]\u001b[A\n",
      "  3%|▎         | 9/356 [00:00<00:11, 30.86it/s]\u001b[A\n",
      "  4%|▍         | 14/356 [00:00<00:09, 34.81it/s]\u001b[A\n",
      "  6%|▌         | 20/356 [00:00<00:08, 38.88it/s]\u001b[A\n",
      "  7%|▋         | 25/356 [00:00<00:08, 41.00it/s]\u001b[A\n",
      "  9%|▊         | 31/356 [00:00<00:07, 44.20it/s]\u001b[A\n",
      " 10%|█         | 37/356 [00:00<00:06, 47.76it/s]\u001b[A\n",
      " 12%|█▏        | 43/356 [00:00<00:06, 49.90it/s]\u001b[A\n",
      " 14%|█▍        | 49/356 [00:00<00:05, 51.29it/s]\u001b[A\n",
      " 15%|█▌        | 55/356 [00:01<00:06, 49.04it/s]\u001b[A\n",
      " 17%|█▋        | 60/356 [00:01<00:06, 48.29it/s]\u001b[A\n",
      " 18%|█▊        | 65/356 [00:01<00:06, 48.06it/s]\u001b[A\n",
      " 20%|█▉        | 71/356 [00:01<00:05, 50.08it/s]\u001b[A\n",
      " 22%|██▏       | 77/356 [00:01<00:05, 51.07it/s]\u001b[A\n",
      " 23%|██▎       | 83/356 [00:01<00:05, 51.89it/s]\u001b[A\n",
      " 25%|██▌       | 89/356 [00:01<00:05, 51.05it/s]\u001b[A\n",
      " 27%|██▋       | 95/356 [00:01<00:05, 51.63it/s]\u001b[A\n",
      " 28%|██▊       | 101/356 [00:02<00:05, 48.42it/s]\u001b[A\n",
      " 30%|██▉       | 106/356 [00:02<00:05, 47.38it/s]\u001b[A\n",
      " 31%|███▏      | 112/356 [00:02<00:04, 50.49it/s]\u001b[A\n",
      " 33%|███▎      | 118/356 [00:02<00:04, 50.08it/s]\u001b[A\n",
      " 35%|███▍      | 124/356 [00:02<00:04, 50.52it/s]\u001b[A\n",
      " 37%|███▋      | 130/356 [00:02<00:04, 52.04it/s]\u001b[A\n",
      " 38%|███▊      | 136/356 [00:02<00:04, 51.87it/s]\u001b[A\n",
      " 40%|███▉      | 142/356 [00:02<00:04, 51.73it/s]\u001b[A\n",
      " 42%|████▏     | 148/356 [00:02<00:03, 53.61it/s]\u001b[A\n",
      " 43%|████▎     | 154/356 [00:03<00:03, 54.04it/s]\u001b[A\n",
      " 45%|████▍     | 160/356 [00:03<00:03, 54.01it/s]\u001b[A\n",
      " 47%|████▋     | 166/356 [00:03<00:03, 52.31it/s]\u001b[A\n",
      " 48%|████▊     | 172/356 [00:03<00:03, 53.03it/s]\u001b[A\n",
      " 50%|█████     | 178/356 [00:03<00:03, 54.21it/s]\u001b[A\n",
      " 52%|█████▏    | 184/356 [00:03<00:03, 53.23it/s]\u001b[A\n",
      " 53%|█████▎    | 190/356 [00:03<00:03, 50.11it/s]\u001b[A\n",
      " 55%|█████▌    | 196/356 [00:03<00:03, 51.80it/s]\u001b[A\n",
      " 57%|█████▋    | 202/356 [00:03<00:03, 50.69it/s]\u001b[A\n",
      " 58%|█████▊    | 208/356 [00:04<00:02, 50.70it/s]\u001b[A\n",
      " 60%|██████    | 214/356 [00:04<00:02, 51.51it/s]\u001b[A\n",
      " 62%|██████▏   | 220/356 [00:04<00:02, 52.77it/s]\u001b[A\n",
      " 63%|██████▎   | 226/356 [00:04<00:02, 51.94it/s]\u001b[A\n",
      " 65%|██████▌   | 232/356 [00:04<00:02, 51.96it/s]\u001b[A\n",
      " 67%|██████▋   | 238/356 [00:04<00:02, 51.10it/s]\u001b[A\n",
      " 69%|██████▊   | 244/356 [00:04<00:02, 51.91it/s]\u001b[A\n",
      " 70%|███████   | 250/356 [00:04<00:02, 52.56it/s]\u001b[A\n",
      " 72%|███████▏  | 256/356 [00:04<00:01, 53.41it/s]\u001b[A\n",
      " 74%|███████▎  | 262/356 [00:05<00:01, 53.02it/s]\u001b[A\n",
      " 75%|███████▌  | 268/356 [00:05<00:01, 53.08it/s]\u001b[A\n",
      " 77%|███████▋  | 274/356 [00:05<00:01, 53.12it/s]\u001b[A\n",
      " 79%|███████▊  | 280/356 [00:05<00:01, 50.92it/s]\u001b[A\n",
      " 80%|████████  | 286/356 [00:05<00:01, 51.89it/s]\u001b[A\n",
      " 82%|████████▏ | 292/356 [00:05<00:01, 51.52it/s]\u001b[A\n",
      " 84%|████████▎ | 298/356 [00:05<00:01, 50.92it/s]\u001b[A\n",
      " 85%|████████▌ | 304/356 [00:05<00:01, 51.41it/s]\u001b[A\n",
      " 87%|████████▋ | 310/356 [00:06<00:00, 51.84it/s]\u001b[A\n",
      " 89%|████████▉ | 316/356 [00:06<00:00, 52.78it/s]\u001b[A\n",
      " 90%|█████████ | 322/356 [00:06<00:00, 52.49it/s]\u001b[A\n",
      " 92%|█████████▏| 328/356 [00:06<00:00, 52.21it/s]\u001b[A\n",
      " 94%|█████████▍| 334/356 [00:06<00:00, 52.72it/s]\u001b[A\n",
      " 96%|█████████▌| 340/356 [00:06<00:00, 51.96it/s]\u001b[A\n",
      " 97%|█████████▋| 346/356 [00:06<00:00, 50.84it/s]\u001b[A\n",
      " 99%|█████████▉| 352/356 [00:06<00:00, 49.78it/s]\u001b[A\n",
      "100%|██████████| 356/356 [00:06<00:00, 51.32it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# countries = set()\n",
    "\n",
    "# for x in tqdm(glob('datapoints/*.csv')):\n",
    "    \n",
    "   \n",
    "#     data = pd.read_csv(x)\n",
    "#     for j in data['country'].values:\n",
    "#         countries.add(j)\n",
    "# res = pd.DataFrame()\n",
    "# res['name'] = list(countries)\n",
    "# res.to_csv(\"distinct_countries_standardized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 1/13 [00:10<02:02, 10.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 2/13 [00:32<02:32, 13.82s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 3/13 [01:08<03:25, 20.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 4/13 [01:45<03:48, 25.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 5/13 [01:53<02:42, 20.28s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 6/13 [02:15<02:25, 20.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 7/13 [02:24<01:44, 17.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 8/13 [03:01<01:55, 23.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 9/13 [03:22<01:30, 22.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 10/13 [03:32<00:55, 18.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 11/13 [03:53<00:39, 19.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 12/13 [04:15<00:20, 20.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 13/13 [04:36<00:00, 20.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 441.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "33it [00:00, 328.38it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "73it [00:00, 332.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "117it [00:00, 358.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "158it [00:00, 370.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "208it [00:00, 318.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "254it [00:00, 349.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "292it [00:00, 356.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "340it [00:00, 386.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "382it [00:01, 395.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "426it [00:01, 407.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "467it [00:01, 404.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "512it [00:01, 414.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "555it [00:01, 418.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "597it [00:01, 403.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "638it [00:01, 400.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "679it [00:01, 391.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "722it [00:01, 401.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "765it [00:01, 408.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "813it [00:02, 425.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "859it [00:02, 433.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "907it [00:02, 444.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "956it [00:02, 456.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "1002it [00:02, 443.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "1047it [00:02, 442.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "1092it [00:02, 444.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "1137it [00:02, 440.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "1182it [00:02, 415.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "1224it [00:03, 412.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "1267it [00:03, 417.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "1310it [00:03, 420.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "1355it [00:03, 429.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "1399it [00:03, 409.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "1444it [00:03, 408.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/1444 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/1444 [00:27<11:07:15, 27.74s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2a197411ce98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mentity_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'db_entity_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 data = sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 262\u001b[0;31m                                       raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# we will try to copy be-definition here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, take_fast_path, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    702\u001b[0m                                        isinstance(subarr, np.ndarray))):\n\u001b[1;32m    703\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_1d_object_array_from_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_extension_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             subarr = construct_1d_ndarray_preserving_na(subarr, dtype,\n\u001b[1;32m    706\u001b[0m                                                         copy=copy)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_type\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \"\"\"\n\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1693\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \"\"\"\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCCategorical\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m            \u001b[0mconditions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         if isinstance(dtype, (ABCSeries, ABCIndexClass,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with connection as c:\n",
    "    db = DBUtils(c)\n",
    "    \n",
    "    entities = pd.read_csv(\"distinct_countries_standardized.csv\")\n",
    "    \n",
    "    new_entities = entities[entities['db_entity_id'].isnull()]\n",
    "    for _, entity in new_entities.iterrows():\n",
    "        entity_id = entity.name\n",
    "        entity_name = entity['name']\n",
    "        db_entity_id = db.get_or_create_entity(entity_name)\n",
    "        entities.loc[entity_id, 'db_entity_id'] = db_entity_id\n",
    "    \n",
    "    # upsert datasets\n",
    "    dataset_name_ids = {}\n",
    "    for f in tqdm(glob('data/*.xlsx')):\n",
    "        \n",
    "        data = pd.read_excel(f)\n",
    "        val = data[data.columns[0]][8]\n",
    "        index_to_remove = val.find(\":\")\n",
    "        res = \"UN WPP - \" + val[index_to_remove+2:]\n",
    "        dataset_id = db.upsert_dataset(name=res, namespace=\"unwpp\", user_id=15)\n",
    "        dataset_name_ids[res] = dataset_id\n",
    "        \n",
    "    # upsert sources\n",
    "    \n",
    "    dataset_to_source_ids = {}\n",
    "    source_name = \"United Nations – Population Division (2019 Revision)\"\n",
    "    for addInfo, dataset_name in tqdm(datasets_dict.items()):\n",
    "        description = {}\n",
    "        description['dataPublishedBy'] = \"United Nations, Department of Economic and Social Affairs, Population Division (2019). World Population Prospects: The 2019 Revision, DVD Edition.\"\n",
    "        description['dataPublisherSource'] = None\n",
    "        description['link'] = 'https://population.un.org/wpp2019/Download/Standard/Interpolated/'\n",
    "        description['retrievedDate'] = datetime.datetime.now().strftime(\"%d-%b-%Y\")\n",
    "        description['additionalInfo'] = addInfo\n",
    "        \n",
    "        source_id = db.upsert_source(name=source_name, description=json.dumps(description), dataset_id=dataset_name_ids[dataset_name])\n",
    "        dataset_to_source_ids[dataset_name] = source_id\n",
    "        \n",
    "    \n",
    "    variables = pd.read_csv('variables.csv')\n",
    "    datasets = pd.read_csv('datasets.csv')\n",
    "    names_to_ids = {}\n",
    "    for i, row in tqdm(variables.iterrows()):\n",
    "        \n",
    "        dataset_name = datasets[datasets['id'] == row['dataset_id']]['name'].values[0]\n",
    "        dataset_id = dataset_name_ids[dataset_name]\n",
    "        source_id = dataset_to_source_ids[dataset_name]\n",
    "\n",
    "        \n",
    "        variable_id = db.upsert_variable(\n",
    "                                        name=row['name'], \n",
    "                                        code=None, \n",
    "                                        unit=row['unit'], \n",
    "                                        short_unit=None, \n",
    "                                        source_id=source_id, \n",
    "                                        dataset_id=dataset_id, \n",
    "                                        description=None, \n",
    "                                        timespan='', \n",
    "                                        coverage='', \n",
    "                                        display={}\n",
    "                                        )\n",
    "        names_to_ids[row['name']] = variable_id\n",
    "        \n",
    "    #Inserting datapoints\n",
    "\n",
    "\n",
    "    datapoints_files = glob(\"datapoints/*.csv\")\n",
    "    for x in tqdm(datapoints_files): \n",
    "        # to get variable is\n",
    "        v_id = int(x.split(\"_\")[1].split(\".\")[0])\n",
    "       \n",
    "        # to get variable name\n",
    "        variable_name = variables[variables['id']==v_id]['name'].values[0]\n",
    "       \n",
    "        # to get variable id from db\n",
    "        variable_id = names_to_ids[variable_name]\n",
    "        data = pd.read_csv(x)\n",
    "\n",
    "        for i, row in data.iterrows():\n",
    "            entity_id = entities[entities['name'] == row['country']]['db_entity_id'].values[0]\n",
    "            if not pd.notnull(row['value']):\n",
    "                val = 0.0\n",
    "            else:\n",
    "                val = row['value']\n",
    "\n",
    "            year = row['year']\n",
    "\n",
    "            db.upsert_one(\"\"\"\n",
    "                INSERT INTO data_values\n",
    "                    (value, year, entityId, variableId)\n",
    "                VALUES\n",
    "                    (%s, %s, %s, %s)\n",
    "                ON DUPLICATE KEY UPDATE\n",
    "                    value = VALUES(value),\n",
    "                    year = VALUES(year),\n",
    "                    entityId = VALUES(entityId),\n",
    "                    variableId = VALUES(variableId)\n",
    "            \"\"\", [val, int(year), str(int(entity_id)), str(variable_id)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
