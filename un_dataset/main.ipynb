{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/alex/Downloads/stats/\")\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from db import connection\n",
    "from db_utils import DBUtils\n",
    "import xlrd\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['UN WPP - Total population (both sexes combined) by single age, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "        'UN WPP - Male population by single age, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "         'UN WPP - Female population by single age, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "         'UN WPP - Interpolated demographic indicators by region, subregion and country, annually for 1950-2099',\n",
    "          'UN WPP - Interpolated total population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "          'UN WPP - Interpolated male population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "          'UN WPP - Interpolated female population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)',\n",
    "          'UN WPP - Percentage of total population by broad age group, region, subregion and country, annually interpolated for 1950-2100',\n",
    "          'UN WPP - Percentage of male total population by broad age group, region, subregion and country, annually interpolated for 1950-2100',\n",
    "          'UN WPP - Percentage of female total population by broad age group, region, subregion and country, annually interpolated for 1950-2100',\n",
    "          'UN WPP - Dependency ratios (total, child, old-age) for different age groups and for both sexes combined by region, subregion and country, annually interpolated for 1950-2100',\n",
    "          'UN WPP - Male dependency ratios (total, child, old-age) for different age groups by region, subregion and country, annually interpolated for 1950-2100',\n",
    "          'UN WPP - Female dependency ratios (total, child, old-age) for different age groups by region, subregion and country, annually interpolated for 1950-2100'\n",
    "         ]\n",
    "\n",
    "keys = ['Annual population by single age - Both Sexes. De facto population as of 1 July of the year indicated classified by single age (0, 1, 2, ..., 99, 100+). Data are presented in thousands.',\n",
    "       'Annual population by single age - Male. De facto population as of 1 July of the year indicated classified by single age (0, 1, 2, ..., 99, 100+). Data are presented in thousands.',\n",
    "       'Annual population by single age - Female. De facto population as of 1 July of the year indicated classified by single age (0, 1, 2, ..., 99, 100+). Data are presented in thousands.',\n",
    "       'Annually interpolated demographic indicators.',\n",
    "       'Annual total population (both sexes combined) by broad age groups. Data are presented in thousands.',\n",
    "       'Annual male population by broad age groups. Data are presented in thousands.',\n",
    "        'Annual female population by broad age groups. Data are presented in thousands.',\n",
    "        'Percentage of annual total population (both sexes combined) by broad age group.',\n",
    "        'Percentage of annual male total population by broad age groups.',\n",
    "        'Percentage of annual female total population by broad age groups.',\n",
    "        'Annual dependency ratios (total, child, old-age) for different age groups and for both sexes combined.',\n",
    "        'Annual male dependency ratios (total, child, old-age) for different age groups.',\n",
    "        'Annual female dependency ratios (total, child, old-age) for different age groups.'\n",
    "       ]\n",
    "datasets_dict = {}\n",
    "for x,y in zip(keys, values):\n",
    "    datasets_dict[x] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with connection as c:\n",
    "#     db = DBUtils(c)\n",
    "    \n",
    "#     # upsert datasets\n",
    "#     dataset_name_ids = {}\n",
    "#     for f in tqdm(os.listdir('sources/')):\n",
    "#         if f == '.DS_Store':\n",
    "#             continue\n",
    "#         data = pd.read_excel('sources/'+f)\n",
    "#         val = data[data.columns[0]][8]\n",
    "#         index_to_remove = val.find(\":\")\n",
    "#         res = \"UN WPP - \" + val[index_to_remove+2:]\n",
    "#         dataset_id = db.upsert_dataset(name=res, namespace=\"unwpp\", user_id=15)\n",
    "#         dataset_name_ids[res] = dataset_id\n",
    "        \n",
    "#     # upsert sources\n",
    "    \n",
    "#     dataset_to_source_ids = {}\n",
    "#     source_name = \"United Nations – Population Division (2019 Revision)\"\n",
    "#     for addInfo, dataset_name in datasets_dict.items():\n",
    "#         description = {}\n",
    "#         description['dataPublishedBy'] = \"United Nations, Department of Economic and Social Affairs, Population Division (2019). World Population Prospects: The 2019 Revision, DVD Edition.\"\n",
    "#         description['dataPublisherSource'] = None\n",
    "#         description['link'] = 'https://population.un.org/wpp2019/Download/Standard/Interpolated/'\n",
    "#         description['retrievedDate'] = datetime.datetime.now().strftime(\"%d-%b-%Y\")\n",
    "#         description['additionalInfo'] = addInfo\n",
    "        \n",
    "#         source_id = db.upsert_source(name=source_name, description=json.dumps(description), dataset_id=dataset_name_ids[dataset_name])\n",
    "#         dataset_to_source_ids[dataset_name_ids[dataset_name]] = source_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_to_source_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [04:45<00:00, 20.77s/it]\n"
     ]
    }
   ],
   "source": [
    "names,ids = [], []\n",
    "i = 0\n",
    "for f in tqdm(glob('data/*.xlsx')):\n",
    "    \n",
    "        data = pd.read_excel(f)\n",
    "        val = data[data.columns[0]][8]\n",
    "        index_to_remove = val.find(\":\")\n",
    "        res = \"UN WPP - \" + val[index_to_remove+2:]\n",
    "        names.append(res)\n",
    "        ids.append(i)\n",
    "        i+=1\n",
    "datasets = pd.DataFrame()\n",
    "datasets['id'] = ids\n",
    "datasets['name'] = names\n",
    "datasets.to_csv('datasets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, desc, d_ids = [], [], []\n",
    "\n",
    "source_name = \"United Nations – Population Division (2019 Revision)\"\n",
    "for addInfo, dataset_name in datasets_dict.items():\n",
    "    description = {}\n",
    "    description['dataPublishedBy'] = \"United Nations, Department of Economic and Social Affairs, Population Division (2019). World Population Prospects: The 2019 Revision, DVD Edition.\"\n",
    "    description['dataPublisherSource'] = None\n",
    "    description['link'] = 'https://population.un.org/wpp2019/Download/Standard/Interpolated/'\n",
    "    description['retrievedDate'] = datetime.datetime.now().strftime(\"%d-%b-%Y\")\n",
    "    description['additionalInfo'] = addInfo\n",
    "    dataset_id = datasets[datasets['name'] == dataset_name]['id'].values[0]\n",
    "\n",
    "    names.append(source_name)\n",
    "    desc.append(description)\n",
    "    d_ids.append(dataset_id)\n",
    "    \n",
    "res = pd.DataFrame()\n",
    "res['name'] = names\n",
    "res['description'] = desc\n",
    "res['dataset_id'] = d_ids\n",
    "res.to_csv(\"sources.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataVariables():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        self.i = 0\n",
    "        self.ids = []\n",
    "        self.names = []\n",
    "        self.units = []\n",
    "        self.dataset_ids = []\n",
    "        self.doc_to_unit = {\n",
    "                        \"UN WPP - Female population by single age, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\",\n",
    "                        \"UN WPP - Male population by single age, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\",\n",
    "            \"UN WPP - Total population (both sexes combined) by single age, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\",\n",
    "            \"UN WPP - Female dependency ratios (total, child, old-age) for different age groups by region, subregion and country, annually interpolated for 1950-2100\": \"Female dependency ratios for different age groups\",\n",
    "            \"UN WPP - Male dependency ratios (total, child, old-age) for different age groups by region, subregion and country, annually interpolated for 1950-2100\": \"Male dependency ratios for different age groups\",\n",
    "            \"UN WPP - Dependency ratios (total, child, old-age) for different age groups and for both sexes combined by region, subregion and country, annually interpolated for 1950-2100\": \"Dependency ratios (both sexes combined) for different age groups\",\n",
    "            \"UN WPP - Percentage of female total population by broad age group, region, subregion and country, annually interpolated for 1950-2100\": \"Percentage\",\n",
    "            \"UN WPP - Percentage of male total population by broad age group, region, subregion and country, annually interpolated for 1950-2100\": \"Percentage\",\n",
    "            \"UN WPP - Percentage of total population by broad age group, region, subregion and country, annually interpolated for 1950-2100\": \"Percentage\",\n",
    "            \"UN WPP - Interpolated female population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\",\n",
    "            \"UN WPP - Interpolated male population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\",\n",
    "            \"UN WPP - Interpolated total population by broad age group, region, subregion and country, annually for 1950-2100 (thousands)\": \"Thousands\"\n",
    "            #UN WPP - Interpolated demographic indicators by region, subregion and country, annually for 1950-2099\n",
    "                   \n",
    "\n",
    "                    }\n",
    "        \n",
    "        self.datasets = pd.read_csv('datasets.csv')\n",
    "        self.df = pd.DataFrame()\n",
    "    \n",
    "        \n",
    "    def get_variables(self, path, skiprows=8, prefix=None):\n",
    "        \n",
    "        for sh in [\"ESTIMATES\", \"MEDIUM VARIANT\"]:\n",
    "            data = pd.read_excel(path, skiprows=skiprows, sheet_name=sh)\n",
    "\n",
    "            val = data[data.columns[0]][0]\n",
    "            index_to_remove = val.find(\":\")\n",
    "            res = \"UN WPP - \" + val[index_to_remove+2:]\n",
    "\n",
    "            title = data[data.columns[0]][1]\n",
    "            print(title)\n",
    "\n",
    "            for item in data.loc[7, data.columns[8]: data.columns[-1]].values:\n",
    "                if prefix:\n",
    "                    self.names.append(title + \": \" + prefix + \" - \" + item)\n",
    "                else:\n",
    "                    self.names.append(title + \": \" + item)\n",
    "                self.ids.append(self.i)\n",
    "                self.i+=1\n",
    "                self.units.append(self.doc_to_unit[res])\n",
    "                self.dataset_ids.append(self.datasets[self.datasets['name'] == res]['id'].values[0])\n",
    "    \n",
    "    def get_custom_variable(self, path, skiprows=8, prefix=None):\n",
    "        \n",
    "        column_unit = {\n",
    "            8: \"Thousands\",\n",
    "            9: \"Thousands\",\n",
    "            10: \"Thousands\",\n",
    "            11: \"Percentage\",\n",
    "            12: \"Years\",\n",
    "            13: \"Years\",\n",
    "            14: \"Years\",\n",
    "            15: \"Thousands\",\n",
    "            16: \"Infant deaths per 1,000 live births\",\n",
    "            17: \"Deaths under age 5 per 1,000 live births\",\n",
    "            18: \"Thousands\",\n",
    "            19: \"Births per 1,000 population\",\n",
    "            20: \"Live births per woman\",\n",
    "            21: \"Thousands\",\n",
    "            22: \"Per 1,000 population\",\n",
    "            23: \"Thousands\",\n",
    "            24: \"Percentage\"\n",
    "            \n",
    "        \n",
    "        }\n",
    "        \n",
    "        for sh in [\"ESTIMATES\", \"MEDIUM VARIANT\"]:\n",
    "            data = pd.read_excel(path, skiprows=skiprows, sheet_name=sh)\n",
    "\n",
    "            val = data[data.columns[0]][0]\n",
    "            index_to_remove = val.find(\":\")\n",
    "            res = \"UN WPP - \" + val[index_to_remove+2:]\n",
    "\n",
    "            title = data[data.columns[0]][1]\n",
    "            print(title)\n",
    "            \n",
    "            col_index = 8\n",
    "            for item in data.loc[7, data.columns[8]: data.columns[-1]].values:\n",
    "                if prefix:\n",
    "                    self.names.append(title + \": \" + prefix + \" - \" + item)\n",
    "                else:\n",
    "                    self.names.append(title + \": \" + item)\n",
    "                self.ids.append(self.i)\n",
    "                self.i+=1\n",
    "                self.units.append(column_unit[col_index])\n",
    "                self.dataset_ids.append(self.datasets[self.datasets['name'] == res]['id'].values[0])\n",
    "                col_index += 1\n",
    "           \n",
    "    \n",
    "\n",
    "            \n",
    "            \n",
    "    def get_df(self):\n",
    "        \n",
    "        self.df['id'] = self.ids\n",
    "        self.df['name'] = self.names\n",
    "        self.df['unit'] = self.units\n",
    "        self.df['dataset_id'] = self.dataset_ids\n",
    "        \n",
    "        return self.df\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_prefix = {\n",
    "    \"data/WPP2019_INT_F03_3_POPULATION_BY_AGE_ANNUAL_FEMALE.xlsx\": \"Female population by age (thousands)\",\n",
    "    \"data/WPP2019_INT_F03_2_POPULATION_BY_AGE_ANNUAL_MALE.xlsx\": \"Male population by age (thousands)\",\n",
    "    \"data/WPP2019_INT_F03_1_POPULATION_BY_AGE_ANNUAL_BOTH_SEXES.xlsx\": \"Total population by age, both sexes combined (thousands)\",\n",
    "    \"data/WPP2019_INT_F02C_3_ANNUAL_POPULATION_INDICATORS_DEPENDENCY_RATIOS_FEMALE.xlsx\": \"Female dependency ratios for different age groups\",\n",
    "    \"data/WPP2019_INT_F02C_2_ANNUAL_POPULATION_INDICATORS_DEPENDENCY_RATIOS_MALE.xlsx\": \"Male dependency ratios for different age groups\",\n",
    "    \"data/WPP2019_INT_F02C_1_ANNUAL_POPULATION_INDICATORS_DEPENDENCY_RATIOS_BOTH_SEXES.xlsx\": \"Dependency ratios (both sexes combined) for different age groups\",\n",
    "    \"data/WPP2019_INT_F02B_3_ANNUAL_POPULATION_INDICATORS_PERCENTAGE_FEMALE.xlsx\": \"Percentage of female population by broad age group (per 100 female total population)\",\n",
    "    \"data/WPP2019_INT_F02B_2_ANNUAL_POPULATION_INDICATORS_PERCENTAGE_MALE.xlsx\": \"Percentage of male population by broad age group (per 100 male total population)\",\n",
    "    \"data/WPP2019_INT_F02B_1_ANNUAL_POPULATION_INDICATORS_PERCENTAGE_BOTH_SEXES.xlsx\": \"Percentage of total population by broad age group, both sexes combined (per 100 total population)\",\n",
    "    \"data/WPP2019_INT_F02A_3_ANNUAL_POPULATION_INDICATORS_FEMALE.xlsx\": \"Female population by broad age group (thousands)\",\n",
    "    \"data/WPP2019_INT_F02A_2_ANNUAL_POPULATION_INDICATORS_MALE.xlsx\": \"Male population by broad age group (thousands)\",\n",
    "    \"data/WPP2019_INT_F02A_1_ANNUAL_POPULATION_INDICATORS_BOTH_SEXES.xlsx\": \"Total population by broad age group, both sexes combined (thousands)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 1/13 [00:20<04:03, 20.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 2/13 [01:07<05:10, 28.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 3/13 [02:25<07:12, 43.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███       | 4/13 [03:42<08:00, 53.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 5/13 [03:59<05:39, 42.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2099\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 6/13 [04:42<04:59, 42.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 7/13 [05:01<03:33, 35.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 8/13 [06:20<04:02, 48.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████▉   | 9/13 [07:05<03:10, 47.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 10/13 [07:25<01:57, 39.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▍ | 11/13 [08:08<01:20, 40.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 12/13 [08:52<00:41, 41.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n",
      "Estimates, 1950 - 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 13/13 [09:36<00:00, 42.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium fertility variant, 2020 - 2100\n"
     ]
    }
   ],
   "source": [
    "dv = DataVariables()\n",
    "for f in tqdm(glob('data/*.xlsx')):\n",
    "     \n",
    "        if f == \"data/WPP2019_INT_F01_ANNUAL_DEMOGRAPHIC_INDICATORS.xlsx\":\n",
    "            dv.get_custom_variable(f, prefix=\"Annually interpolated demographic indicators\")\n",
    "        else:\n",
    "            dv.get_variables(f, prefix=name_to_prefix[f])    \n",
    "    \n",
    "        \n",
    "\n",
    "res = dv.get_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"variables.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_country(row):\n",
    "        \n",
    "        row['country'] = row['country'].str.replace(r'\\s*[^A-Za-z\\s]*$', '')\n",
    "        return row\n",
    "\n",
    "\n",
    "def get_variables(path, variables, skiprows=8, prefix=None, custom=False):\n",
    "        \n",
    "        for sh in [\"ESTIMATES\", \"MEDIUM VARIANT\"]:\n",
    "            data = pd.read_excel(path, skiprows=skiprows, sheet_name=sh)\n",
    "\n",
    "            val = data[data.columns[0]][0]\n",
    "            index_to_remove = val.find(\":\")\n",
    "            res = \"UN WPP - \" + val[index_to_remove+2:]\n",
    "\n",
    "            title = data[data.columns[0]][1]\n",
    "            \n",
    "            index_col = 8\n",
    "            \n",
    "            for item in data.loc[7, data.columns[8]: data.columns[-1]].values:\n",
    "                \n",
    "                if prefix:\n",
    "                    var_name = title + \": \" + prefix + \" - \" + item\n",
    "                else:\n",
    "                    var_name = title + \": \" + item\n",
    "                \n",
    "                var_id = variables[variables['name'] == var_name]['id'].values[0] \n",
    "                \n",
    "                data2 = data.iloc[8:]\n",
    "               \n",
    "                data_res = pd.DataFrame()\n",
    "                data_res['country'] = data2[data2.columns[2]]\n",
    "                data_res['year'] = data2[data2.columns[7]]\n",
    "                data_res['value'] = data2[\"Unnamed: %s\" % str(index_col)]\n",
    "                \n",
    "                data_res['country'] = normalize_country(data_res)\n",
    "                data_res = data_res[data_res['value'] != '...']\n",
    "                data_res.to_csv('datapoints/datapoints_%s.csv' % str(var_id), index=False)\n",
    "                \n",
    "                index_col += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 1/13 [00:22<04:25, 22.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 2/13 [01:15<05:47, 31.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 3/13 [02:47<08:15, 49.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███       | 4/13 [04:18<09:17, 61.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 5/13 [04:37<06:34, 49.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 6/13 [05:31<05:53, 50.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 7/13 [05:53<04:12, 42.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 8/13 [07:24<04:43, 56.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████▉   | 9/13 [08:17<03:42, 55.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 10/13 [08:39<02:16, 45.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▍ | 11/13 [09:32<01:35, 47.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 12/13 [10:25<00:49, 49.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 13/13 [11:17<00:00, 50.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "variables = pd.read_csv(\"variables.csv\")\n",
    "\n",
    "for f in tqdm(glob('data/*.xlsx')):\n",
    "   \n",
    "    if f == \"data/WPP2019_INT_F01_ANNUAL_DEMOGRAPHIC_INDICATORS.xlsx\":\n",
    "        get_variables(f,variables, prefix=\"Annually interpolated demographic indicators\")\n",
    "    else:\n",
    "        get_variables(f,variables, prefix=name_to_prefix[f])  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get country names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/356 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 3/356 [00:00<00:13, 26.30it/s]\u001b[A\n",
      "  3%|▎         | 9/356 [00:00<00:11, 30.86it/s]\u001b[A\n",
      "  4%|▍         | 14/356 [00:00<00:09, 34.81it/s]\u001b[A\n",
      "  6%|▌         | 20/356 [00:00<00:08, 38.88it/s]\u001b[A\n",
      "  7%|▋         | 25/356 [00:00<00:08, 41.00it/s]\u001b[A\n",
      "  9%|▊         | 31/356 [00:00<00:07, 44.20it/s]\u001b[A\n",
      " 10%|█         | 37/356 [00:00<00:06, 47.76it/s]\u001b[A\n",
      " 12%|█▏        | 43/356 [00:00<00:06, 49.90it/s]\u001b[A\n",
      " 14%|█▍        | 49/356 [00:00<00:05, 51.29it/s]\u001b[A\n",
      " 15%|█▌        | 55/356 [00:01<00:06, 49.04it/s]\u001b[A\n",
      " 17%|█▋        | 60/356 [00:01<00:06, 48.29it/s]\u001b[A\n",
      " 18%|█▊        | 65/356 [00:01<00:06, 48.06it/s]\u001b[A\n",
      " 20%|█▉        | 71/356 [00:01<00:05, 50.08it/s]\u001b[A\n",
      " 22%|██▏       | 77/356 [00:01<00:05, 51.07it/s]\u001b[A\n",
      " 23%|██▎       | 83/356 [00:01<00:05, 51.89it/s]\u001b[A\n",
      " 25%|██▌       | 89/356 [00:01<00:05, 51.05it/s]\u001b[A\n",
      " 27%|██▋       | 95/356 [00:01<00:05, 51.63it/s]\u001b[A\n",
      " 28%|██▊       | 101/356 [00:02<00:05, 48.42it/s]\u001b[A\n",
      " 30%|██▉       | 106/356 [00:02<00:05, 47.38it/s]\u001b[A\n",
      " 31%|███▏      | 112/356 [00:02<00:04, 50.49it/s]\u001b[A\n",
      " 33%|███▎      | 118/356 [00:02<00:04, 50.08it/s]\u001b[A\n",
      " 35%|███▍      | 124/356 [00:02<00:04, 50.52it/s]\u001b[A\n",
      " 37%|███▋      | 130/356 [00:02<00:04, 52.04it/s]\u001b[A\n",
      " 38%|███▊      | 136/356 [00:02<00:04, 51.87it/s]\u001b[A\n",
      " 40%|███▉      | 142/356 [00:02<00:04, 51.73it/s]\u001b[A\n",
      " 42%|████▏     | 148/356 [00:02<00:03, 53.61it/s]\u001b[A\n",
      " 43%|████▎     | 154/356 [00:03<00:03, 54.04it/s]\u001b[A\n",
      " 45%|████▍     | 160/356 [00:03<00:03, 54.01it/s]\u001b[A\n",
      " 47%|████▋     | 166/356 [00:03<00:03, 52.31it/s]\u001b[A\n",
      " 48%|████▊     | 172/356 [00:03<00:03, 53.03it/s]\u001b[A\n",
      " 50%|█████     | 178/356 [00:03<00:03, 54.21it/s]\u001b[A\n",
      " 52%|█████▏    | 184/356 [00:03<00:03, 53.23it/s]\u001b[A\n",
      " 53%|█████▎    | 190/356 [00:03<00:03, 50.11it/s]\u001b[A\n",
      " 55%|█████▌    | 196/356 [00:03<00:03, 51.80it/s]\u001b[A\n",
      " 57%|█████▋    | 202/356 [00:03<00:03, 50.69it/s]\u001b[A\n",
      " 58%|█████▊    | 208/356 [00:04<00:02, 50.70it/s]\u001b[A\n",
      " 60%|██████    | 214/356 [00:04<00:02, 51.51it/s]\u001b[A\n",
      " 62%|██████▏   | 220/356 [00:04<00:02, 52.77it/s]\u001b[A\n",
      " 63%|██████▎   | 226/356 [00:04<00:02, 51.94it/s]\u001b[A\n",
      " 65%|██████▌   | 232/356 [00:04<00:02, 51.96it/s]\u001b[A\n",
      " 67%|██████▋   | 238/356 [00:04<00:02, 51.10it/s]\u001b[A\n",
      " 69%|██████▊   | 244/356 [00:04<00:02, 51.91it/s]\u001b[A\n",
      " 70%|███████   | 250/356 [00:04<00:02, 52.56it/s]\u001b[A\n",
      " 72%|███████▏  | 256/356 [00:04<00:01, 53.41it/s]\u001b[A\n",
      " 74%|███████▎  | 262/356 [00:05<00:01, 53.02it/s]\u001b[A\n",
      " 75%|███████▌  | 268/356 [00:05<00:01, 53.08it/s]\u001b[A\n",
      " 77%|███████▋  | 274/356 [00:05<00:01, 53.12it/s]\u001b[A\n",
      " 79%|███████▊  | 280/356 [00:05<00:01, 50.92it/s]\u001b[A\n",
      " 80%|████████  | 286/356 [00:05<00:01, 51.89it/s]\u001b[A\n",
      " 82%|████████▏ | 292/356 [00:05<00:01, 51.52it/s]\u001b[A\n",
      " 84%|████████▎ | 298/356 [00:05<00:01, 50.92it/s]\u001b[A\n",
      " 85%|████████▌ | 304/356 [00:05<00:01, 51.41it/s]\u001b[A\n",
      " 87%|████████▋ | 310/356 [00:06<00:00, 51.84it/s]\u001b[A\n",
      " 89%|████████▉ | 316/356 [00:06<00:00, 52.78it/s]\u001b[A\n",
      " 90%|█████████ | 322/356 [00:06<00:00, 52.49it/s]\u001b[A\n",
      " 92%|█████████▏| 328/356 [00:06<00:00, 52.21it/s]\u001b[A\n",
      " 94%|█████████▍| 334/356 [00:06<00:00, 52.72it/s]\u001b[A\n",
      " 96%|█████████▌| 340/356 [00:06<00:00, 51.96it/s]\u001b[A\n",
      " 97%|█████████▋| 346/356 [00:06<00:00, 50.84it/s]\u001b[A\n",
      " 99%|█████████▉| 352/356 [00:06<00:00, 49.78it/s]\u001b[A\n",
      "100%|██████████| 356/356 [00:06<00:00, 51.32it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# countries = set()\n",
    "\n",
    "# for x in tqdm(glob('datapoints/*.csv')):\n",
    "    \n",
    "   \n",
    "#     data = pd.read_csv(x)\n",
    "#     for j in data['country'].values:\n",
    "#         countries.add(j)\n",
    "# res = pd.DataFrame()\n",
    "# res['name'] = list(countries)\n",
    "# res.to_csv(\"distinct_countries_standardized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterfaceError",
     "evalue": "(0, '')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ffc86f9fe189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mentity_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdb_entity_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_entity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentity_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'db_entity_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_entity_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/stats/db_utils.py\u001b[0m in \u001b[0;36mget_or_create_entity\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# Populate cache from database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefill_entity_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mentity_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_cached_entity_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/stats/db_utils.py\u001b[0m in \u001b[0;36mprefill_entity_cache\u001b[0;34m(self, names)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \"\"\", {\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;34m'country_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnormalize_entity_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         })\n",
      "\u001b[0;32m~/Downloads/stats/db_utils.py\u001b[0m in \u001b[0;36mfetch_many\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogateescape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_execute_command\u001b[0;34m(self, command, sql)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(0, '')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInterfaceError\u001b[0m: (0, '')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ffc86f9fe189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m                     \u001b[0mentityId\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVALUES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentityId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mvariableId\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVALUES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariableId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \"\"\", [val, int(year), str(int(entity_id)), str(variable_id)])\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc, value, traceback)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;34m\"\"\"On successful exit, commit. On exception, rollback\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mrollback\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \"\"\"\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ROLLBACK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_ok_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_execute_command\u001b[0;34m(self, command, sql)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(0, '')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;31m# If the last query was unbuffered, make sure it finishes before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInterfaceError\u001b[0m: (0, '')"
     ]
    }
   ],
   "source": [
    "with connection as c:\n",
    "    db = DBUtils(c)\n",
    "    \n",
    "    entities = pd.read_csv(\"distinct_countries_standardized.csv\")\n",
    "    datasets = pd.read_csv(\"datasets.csv\")\n",
    "    sources = pd.read_csv(\"sources.csv\")\n",
    "    variables = pd.read_csv('variables.csv')\n",
    "    \n",
    "    new_entities = entities[entities['db_entity_id'].isnull()]\n",
    "    for _, entity in new_entities.iterrows():\n",
    "        entity_id = entity.name\n",
    "        entity_name = entity['name']\n",
    "        db_entity_id = db.get_or_create_entity(entity_name)\n",
    "        entities.loc[entity_id, 'db_entity_id'] = db_entity_id\n",
    "    \n",
    "    # upsert datasets\n",
    "    dataset_name_ids = {}\n",
    "    for i, row in tqdm(datasets.iterrows()):\n",
    "        dataset_id = db.upsert_dataset(name=row['name'], namespace=\"unwpp\", user_id=15)\n",
    "        dataset_name_ids[row['name']] = dataset_id\n",
    "        \n",
    "        \n",
    "    # upsert sources\n",
    "    \n",
    "    dataset_to_source_ids = {}\n",
    "    for i, row in tqdm(sources.iterrows()):\n",
    "\n",
    "        dataset_name = datasets[datasets['id'] == row['dataset_id']]['name'].values[0]\n",
    "        source_id = db.upsert_source(name=row['name'], description=json.dumps(row['description']), dataset_id=dataset_name_ids[dataset_name])\n",
    "\n",
    "        dataset_to_source_ids[dataset_name] = source_id\n",
    "\n",
    "        \n",
    "    # upsert variables\n",
    "    names_to_ids = {}\n",
    "    for i, row in tqdm(variables.iterrows()):\n",
    "        \n",
    "        dataset_name = datasets[datasets['id'] == row['dataset_id']]['name'].values[0]\n",
    "        dataset_id = dataset_name_ids[dataset_name]\n",
    "        source_id = dataset_to_source_ids[dataset_name]\n",
    "\n",
    "        \n",
    "        variable_id = db.upsert_variable(\n",
    "                                        name=row['name'], \n",
    "                                        code=None, \n",
    "                                        unit=row['unit'], \n",
    "                                        short_unit=None, \n",
    "                                        source_id=source_id, \n",
    "                                        dataset_id=dataset_id, \n",
    "                                        description=None, \n",
    "                                        timespan='', \n",
    "                                        coverage='', \n",
    "                                        display={}\n",
    "                                        )\n",
    "        names_to_ids[row['name']] = variable_id\n",
    "        \n",
    "    #Inserting datapoints\n",
    "\n",
    "\n",
    "    datapoints_files = glob(\"datapoints/*.csv\")\n",
    "    for x in tqdm(datapoints_files): \n",
    "        # to get variable is\n",
    "        v_id = int(x.split(\"_\")[1].split(\".\")[0])\n",
    "       \n",
    "        # to get variable name\n",
    "        variable_name = variables[variables['id']==v_id]['name'].values[0]\n",
    "       \n",
    "        # to get variable id from db\n",
    "        variable_id = names_to_ids[variable_name]\n",
    "        data = pd.read_csv(x)\n",
    "\n",
    "        for i, row in data.iterrows():\n",
    "            entity_id = entities[entities['name'] == row['country']]['db_entity_id'].values[0]\n",
    "\n",
    "            year = row['year']\n",
    "\n",
    "            db.upsert_one(\"\"\"\n",
    "                INSERT INTO data_values\n",
    "                    (value, year, entityId, variableId)\n",
    "                VALUES\n",
    "                    (%s, %s, %s, %s)\n",
    "                ON DUPLICATE KEY UPDATE\n",
    "                    value = VALUES(value),\n",
    "                    year = VALUES(year),\n",
    "                    entityId = VALUES(entityId),\n",
    "                    variableId = VALUES(variableId)\n",
    "            \"\"\", [val, int(year), str(int(entity_id)), str(variable_id)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
